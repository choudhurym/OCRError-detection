#!/usr/bin/env python3# -*- coding: utf-8 -*-"""Created on Sun Oct 11 21:58:56 2020@author: Muntabir Choudhury"""#importing librariesimport pandas as pdimport numpy as npimport csvfrom sklearn.preprocessing import MaxAbsScalerfrom sklearn.model_selection import train_test_splitfrom sklearn import svmimport xgboostfrom sklearn.metrics import accuracy_scorefrom sklearn import metricsfrom sklearn.ensemble import GradientBoostingClassifierfrom sklearn.metrics import classification_report, confusion_matrixfrom sklearn.feature_extraction.text import TfidfVectorizerfrom sklearn.feature_extraction.text import CountVectorizerfrom sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCVfrom sklearn.linear_model import SGDClassifier#creating a dflist with column name: abstract and label dfList=[]colname=['tokens', 'label']df = pd.read_csv('real_error-word.csv', encoding = "utf-8", header = None)dfList.append(df)concatDf = pd.concat(dfList, axis =0)concatDf.columns=colnameconcatDf.to_csv('real_error-word_update.csv', index = None, header=True, encoding = 'utf-8')# glove_file = "/Users/muntabir/Desktop/Graduate-School-ODU/CS895/project/source/glove.840B.300d.txt"# words = pd.read_table(glove_file, sep=" ", index_col=0, header=None, quoting=csv.QUOTE_NONE)# def vec(w):#   return words.loc[w].as_matrix()  df1 = pd.read_csv("real_error-word_update.csv", encoding = "utf-8")df1 = df1.dropna()df1 = df1.reset_index(drop=True)vectorizer = TfidfVectorizer()#vectorizer = CountVectorizer()vectorizer.fit(df1['tokens'])x = vectorizer.transform(df1['tokens'])y = df1['label'] #target settrain_X, test_X, train_y, test_y = train_test_split(x, y,                                                    stratify=y,                                                    test_size=0.3, random_state = 1)#Gradient Boosting Classifier# lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1]# for learning_rate in lr_list:#     gb_clf = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=1000, max_depth=2, random_state=0)#     gb_clf.fit(train_X,train_y)    #     print("Learning rate: ", learning_rate)#     print("Accuracy score (training): {0:.3f}".format(gb_clf.score(train_X, train_y)))#     print("Accuracy score (validation): {0:.3f}".format(gb_clf.score(test_X, test_y)))# gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=1, max_features=1000, max_depth=2, random_state=0)# gb_clf2.fit(train_X, train_y)# predictions = gb_clf2.predict(test_X)# print("Confusion Matrix:")# print(confusion_matrix(test_y, predictions))# print("Classification Report")# print(classification_report(test_y, predictions))# # XGboost Classifier# model = xgboost.XGBClassifier()# model.fit(train_X, train_y)# y_pred = model.predict(test_X)# predictions = [round(value) for value in y_pred]# accuracy = accuracy_score(test_y, predictions)# print("######### OCR Real Word Train ##############")# print("\n")# print("Train - Gradient Boost Classifier\n")# print("Accuracy: %.2f%%" % (accuracy * 100.0))# print("Precision:",metrics.precision_score(test_y, predictions))# print("Recall:",metrics.recall_score(test_y, predictions))# print("F1:",metrics.f1_score(test_y, predictions))# #Support Vector Machine    # clf = svm.SVC(kernel='linear')# clf.fit(train_X, train_y)# y_pred = clf.predict(test_X)# predictions = [round(value) for value in y_pred]# accuracy = accuracy_score(test_y, predictions)# print("\n")# print("Train - Support Vector Machine\n")# print("Accuracy: %.2f%%" % (accuracy * 100.0))# print("Precision:",metrics.precision_score(test_y, predictions))# print("Recall:",metrics.recall_score(test_y, predictions))# print("F1:",metrics.f1_score(test_y, predictions))param_grid_ = [ {'alpha': [0.0000001, 0.000001, 0.00001, 0.0001, 0.001, 0.01]}]model = GridSearchCV(SGDClassifier(max_iter=2), cv=5, param_grid=param_grid_, scoring='f1_micro', n_jobs=-1, verbose=10)model.fit(train_X, train_y)print(model.cv_results_,'\n\n')print("Best parameters set found on development set:\n") print(model.best_params_,'\n')print("Grid scores on development set:\n") means = model.cv_results_['mean_test_score']stds = model.cv_results_['std_test_score'] for mean, std, params in zip(means, stds, model.cv_results_['params']):    print("%0.3f (+/-%0.03f) for %r" % (mean, std * 2, params))     print('\n\n')    print("Detailed classification report:\n")     print("The model is trained on the full development set.")    print("The scores are computed on the full evaluation set.\n\n")test_y, pred_y = test_y, model.predict(test_X)print(confusion_matrix(test_y, pred_y))print('\n\n')print(classification_report(test_y, pred_y))